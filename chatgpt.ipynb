{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c27479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from playwright.async_api import async_playwright, Locator, Page, Response\n",
    "from playwright_stealth import Stealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910fd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def simulate_user_type(msg:str, msg_input:Locator, page:Page):\n",
    "    msg_words = msg.strip().split('\\n')\n",
    "\n",
    "    for word_idx in range(len(msg_words)):\n",
    "        if msg_words[word_idx] != '':\n",
    "            await msg_input.type(msg_words[word_idx])\n",
    "            if word_idx != len(msg_words) - 1:\n",
    "                await page.keyboard.press('Shift+Enter')\n",
    "        else:\n",
    "            await page.keyboard.press('Shift+Enter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a9ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gpt_response(stream_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Parse the stream response and extract the clean GPT message.\n",
    "    Returns the concatenated text from the assistant's content.\n",
    "    \"\"\"\n",
    "    # Step 1: Clean up prefixes and suffixes\n",
    "    text_tmp1 = stream_text[33:] if stream_text.startswith(\"event: delta_encoding\") else stream_text\n",
    "    text_tmp1 = text_tmp1[7:] if text_tmp1.startswith(\"\\ndata: \") else text_tmp1\n",
    "    if text_tmp1.endswith(\"\\n\\ndata: [DONE]\\n\\n\"):\n",
    "        text_tmp2 = text_tmp1[:-16]\n",
    "    else:\n",
    "        text_tmp2 = text_tmp1\n",
    "    \n",
    "    # Step 2: Split into JSON chunks\n",
    "    text_list = []\n",
    "    for x in text_tmp2.replace(\"event: delta\", \"\").split(\"\\n\\ndata: \"):\n",
    "        if x.strip():  # Skip empty\n",
    "            tmp1 = x.strip()\n",
    "            # Fix if not starting/ending with {} properly\n",
    "            if not tmp1.startswith(\"{\"):\n",
    "                start_index = tmp1.find(\"{\")\n",
    "                if start_index != -1:\n",
    "                    tmp1 = tmp1[start_index:]\n",
    "            if not tmp1.endswith(\"}\"):\n",
    "                end_index = tmp1.rfind(\"}\")\n",
    "                if end_index != -1:\n",
    "                    tmp1 = tmp1[:end_index + 1]\n",
    "            # Try to load as JSON\n",
    "            try:\n",
    "                tmp = json.loads(tmp1)\n",
    "            except json.JSONDecodeError:\n",
    "                # Fix escaped backslashes if needed\n",
    "                tmp2 = tmp1.replace(\"\\\\\\\\\", \"\\\\\")\n",
    "                try:\n",
    "                    tmp = json.loads(tmp2)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue  # Skip invalid chunks\n",
    "            text_list.append(tmp)\n",
    "    \n",
    "    # Step 3: Find start of content and extract text\n",
    "    first_begin = [i for i, msg in enumerate(text_list) if msg.get(\"p\") == \"/message/content/parts/0\"]\n",
    "    begin = first_begin[0] if first_begin else 0\n",
    "    msg_list = \"\"\n",
    "    for index, msg in enumerate(text_list):\n",
    "        if index >= begin:\n",
    "            # Simple string append\n",
    "            if \"v\" in msg and isinstance(msg[\"v\"], str):\n",
    "                msg_list += msg[\"v\"]\n",
    "            # List handling (nested parts)\n",
    "            elif \"v\" in msg and isinstance(msg[\"v\"], list):\n",
    "                for x in msg[\"v\"]:\n",
    "                    if \"p\" in x and x[\"p\"] == \"/message/content/parts/0\" and \"v\" in x:\n",
    "                        msg_list += x[\"v\"]\n",
    "                    # Deeper patch nesting\n",
    "                    if \"p\" in x and x[\"p\"] == \"\" and \"o\" in x and x[\"o\"] == \"patch\" and \"v\" in x and isinstance(x[\"v\"], list):\n",
    "                        for sub in x[\"v\"]:\n",
    "                            if \"p\" in sub and sub[\"p\"] == \"/message/content/parts/0\" and \"v\" in sub:\n",
    "                                msg_list += sub[\"v\"]\n",
    "    \n",
    "    # Step 4: Clean special patterns (if any, like in the original)\n",
    "    if \"turn0\" in msg_list or \"city\" in msg_list:\n",
    "        pattern = r'[\\ue200-\\ue203]?([a-z]+)?[\\ue200-\\ue203](?:turn\\d+(?:image|search|fetch|forecast)\\d+|city)'\n",
    "        msg_list = re.sub(pattern, '', msg_list)\n",
    "    \n",
    "    return msg_list.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afaff65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Response: Hey! Howâ€™s it going?\n"
     ]
    }
   ],
   "source": [
    "async with Stealth().use_async(async_playwright()) as p:\n",
    "    browser = await p.chromium.launch(headless = False)\n",
    "    page = await browser.new_page()\n",
    "    await page.goto(\"https://chatgpt.com/\")\n",
    "\n",
    "    msg_input = page.locator('//textarea[@name=\"prompt-textarea\"]')\n",
    "\n",
    "    msg = 'hi mate'\n",
    "\n",
    "    \n",
    "    await simulate_user_type(msg, msg_input, page)\n",
    "    \n",
    "    async with page.expect_response(\"**/conversation\") as response_info:\n",
    "        await page.locator('//button[@aria-label=\"Send prompt\"]').click()\n",
    "\n",
    "    response = await response_info.value\n",
    "    raw_stream = await response.text()\n",
    "    answer = parse_gpt_response(raw_stream)\n",
    "    print(f\"GPT Response: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
