{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f53a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright, Locator, Page, Response\n",
    "from playwright_stealth import Stealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec97f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def simulate_user_type(msg:str, msg_input:Locator, page:Page):\n",
    "    msg_words = msg.strip().split('\\n')\n",
    "\n",
    "    for word_idx in range(len(msg_words)):\n",
    "        if msg_words[word_idx] != '':\n",
    "            await msg_input.type(msg_words[word_idx])\n",
    "            if word_idx != len(msg_words) - 1:\n",
    "                await page.keyboard.press('Shift+Enter')\n",
    "        else:\n",
    "            await page.keyboard.press('Shift+Enter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c3a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def handle_response(response:Response):\n",
    "    if response.url.endswith('/conversation'):\n",
    "        print(\">>\", response.url)\n",
    "        # res = await response.body()\n",
    "        # print(f'Body: {res}')\n",
    "        # res = await response.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b128a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> https://chatgpt.com/backend-anon/f/conversation\n",
      "Response : b'event: delta_encoding\\ndata: \"v1\"\\n\\nevent: delta\\ndata: {\"p\": \"\", \"o\": \"add\", \"v\": {\"message\": {\"id\": \"c9c43467-98e6-44c3-9833-949081fffc9f\", \"author\": {\"role\": \"system\", \"name\": null, \"metadata\": {}}, \"create_time\": null, \"update_time\": null, \"content\": {\"content_type\": \"text\", \"parts\": [\"\"]}, \"status\": \"finished_successfully\", \"end_turn\": true, \"weight\": 0.0, \"metadata\": {\"is_visually_hidden_from_conversation\": true, \"model_switcher_deny\": []}, \"recipient\": \"all\", \"channel\": null}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\", \"error\": null}, \"c\": 0}     \\n\\nevent: delta\\ndata: {\"v\": {\"message\": {\"id\": \"454b3509-b4a0-406d-8439-8c198db866c3\", \"author\": {\"role\": \"user\", \"name\": null, \"metadata\": {}}, \"create_time\": 1766471186.868, \"update_time\": null, \"content\": {\"content_type\": \"text\", \"parts\": [\"hi\\\\nmate\"]}, \"status\": \"finished_successfully\", \"end_turn\": null, \"weight\": 1.0, \"metadata\": {\"selected_github_repos\": [], \"serialization_metadata\": {\"custom_symbol_offsets\": []}, \"request_id\": \"1d02419d-78d7-4099-8cde-4ffd0829e5d4\", \"message_source\": null, \"turn_exchange_id\": \"de7a7c7d-bd3e-42ac-b563-79bfa48ea32f\", \"model_switcher_deny\": []}, \"recipient\": \"all\", \"channel\": null}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\", \"error\": null}, \"c\": 1}\\n\\ndata: {\"type\": \"input_message\", \"input_message\": {\"id\": \"454b3509-b4a0-406d-8439-8c198db866c3\", \"author\": {\"role\": \"user\", \"name\": null, \"metadata\": {}}, \"create_time\": 1766471186.868, \"update_time\": null, \"content\": {\"content_type\": \"text\", \"parts\": [\"hi\\\\nmate\"]}, \"status\": \"finished_successfully\", \"end_turn\": null, \"weight\": 1.0, \"metadata\": {\"selected_github_repos\": [], \"selected_all_github_repos\": false, \"serialization_metadata\": {\"custom_symbol_offsets\": []}, \"request_id\": \"1d02419d-78d7-4099-8cde-4ffd0829e5d4\", \"message_source\": null, \"turn_exchange_id\": \"de7a7c7d-bd3e-42ac-b563-79bfa48ea32f\", \"useragent\": {\"client_type\": \"web\", \"is_mobile\": false, \"is_mobile_app\": false, \"is_desktop_app\": false, \"is_native_app\": false, \"is_native_app_apple\": false, \"is_mobile_app_ios\": false, \"is_desktop_app_macos\": false, \"is_aura_app_macos\": false, \"is_aura_web\": false, \"is_sora_ios\": false, \"is_agora_ios\": false, \"is_agora_android\": false, \"is_desktop_app_windows\": false, \"is_electron_app\": false, \"is_mobile_app_android\": false, \"is_mobile_web\": false, \"is_mobile_web_ios\": false, \"is_mobile_web_android\": false, \"is_ios\": false, \"is_android\": false, \"is_macos\": false, \"is_windows\": false, \"is_linux\": true, \"is_chatgpt_client\": false, \"is_sora_client\": false, \"is_agora_client\": false, \"is_browserbased_app\": true, \"is_chatgpt_api\": false, \"is_slack\": false, \"is_chatkit_web\": false, \"is_chatkit_synthetic\": false, \"is_kakao_talk\": false, \"app_version\": null, \"build_number\": null, \"user_agent\": \"mozilla/5.0 (x11; linux x86_64) applewebkit/537.36 (khtml, like gecko) chrome/143.0.0.0 safari/537.36\", \"app_environment\": null, \"os_version\": null, \"device_model\": null, \"user_client_type\": \"desktop_web\"}, \"paragen_stream_type\": \"default\", \"parent_id\": \"c9c43467-98e6-44c3-9833-949081fffc9f\"}, \"recipient\": \"all\", \"channel\": null}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\\n\\nevent: delta\\ndata: {\"v\": {\"message\": {\"id\": \"ffb05719-6f26-467d-a4de-7e49fbdc85cb\", \"author\": {\"role\": \"assistant\", \"name\": null, \"metadata\": {}}, \"create_time\": 1766471188.149866, \"update_time\": null, \"content\": {\"content_type\": \"text\", \"parts\": [\"\"]}, \"status\": \"in_progress\", \"end_turn\": null, \"weight\": 1.0, \"metadata\": {\"citations\": [], \"content_references\": [], \"request_id\": \"1d02419d-78d7-4099-8cde-4ffd0829e5d4\", \"message_type\": \"next\", \"model_slug\": \"gpt-5-2\", \"default_model_slug\": \"auto\", \"parent_id\": \"454b3509-b4a0-406d-8439-8c198db866c3\", \"turn_exchange_id\": \"de7a7c7d-bd3e-42ac-b563-79bfa48ea32f\", \"model_switcher_deny\": []}, \"recipient\": \"all\", \"channel\": null}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\", \"error\": null}, \"c\": 2} \\n\\ndata: {\"type\": \"server_ste_metadata\", \"metadata\": {\"conduit_prewarmed\": false, \"plan_type\": \"guest\", \"user_agent\": \"web_desktop\", \"service\": null, \"fast_convo\": true, \"warmup_state\": \"rewarm\", \"is_first_turn\": true, \"cluster_region\": \"ukwest\", \"model_slug\": \"i-mini\", \"region\": null, \"is_multimodal\": false, \"did_auto_switch_to_reasoning\": false, \"auto_switcher_race_winner\": null, \"is_autoswitcher_enabled\": false, \"is_search\": null, \"did_prompt_contain_image\": false, \"search_tool_call_count\": null, \"search_tool_query_types\": null, \"message_id\": \"ffb05719-6f26-467d-a4de-7e49fbdc85cb\", \"request_id\": \"1d02419d-78d7-4099-8cde-4ffd0829e5d4\"}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\\n\\ndata: {\"type\": \"message_marker\", \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\", \"message_id\": \"ffb05719-6f26-467d-a4de-7e49fbdc85cb\", \"marker\": \"user_visible_token\", \"event\": \"first\"}\\n\\nevent: delta\\ndata: {\"p\": \"/message/content/parts/0\", \"o\": \"append\", \"v\": \"Hey! What\\'s\"}    \\n\\nevent: delta\\ndata: {\"v\": \" up, mate\"}      \\n\\nevent: delta\\ndata: {\"v\": \"? How\\\\u2019s it\"}\\n\\nevent: delta\\ndata: {\"p\": \"\", \"o\": \"patch\", \"v\": [{\"p\": \"/message/content/parts/0\", \"o\": \"append\", \"v\": \" going?\"}, {\"p\": \"/message/status\", \"o\": \"replace\", \"v\": \"finished_successfully\"}, {\"p\": \"/message/end_turn\", \"o\": \"replace\", \"v\": true}, {\"p\": \"/message/metadata\", \"o\": \"append\", \"v\": {\"finish_details\": {\"type\": \"stop\", \"stop_tokens\": [200002]}, \"is_complete\": true}}]}     \\n\\ndata: {\"type\": \"message_stream_complete\", \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\\n\\ndata: [DONE]\\n\\n'\n",
      ">> https://chatgpt.com/backend-anon/f/conversation\n",
      "Response : b'event: delta_encoding\\ndata: \"v1\"\\n\\ndata: {\"type\": \"input_message\", \"input_message\": {\"id\": \"101b2a49-34ab-47df-9e37-96039e76c866\", \"author\": {\"role\": \"user\", \"name\": null, \"metadata\": {}}, \"create_time\": 1766471190.75, \"update_time\": null, \"content\": {\"content_type\": \"text\", \"parts\": [\"write factorial function with python and java and explain it and show me a sample table of input and outputs and explain more\"]}, \"status\": \"finished_successfully\", \"end_turn\": null, \"weight\": 1.0, \"metadata\": {\"selected_github_repos\": [], \"selected_all_github_repos\": false, \"serialization_metadata\": {\"custom_symbol_offsets\": []}, \"request_id\": \"5362bbcc-cd03-46e4-9cb0-52cac1de9606\", \"message_source\": null, \"turn_exchange_id\": \"abebc94b-1ccf-4fcb-bc3b-91b8f96b6f68\", \"useragent\": {\"client_type\": \"web\", \"is_mobile\": false, \"is_mobile_app\": false, \"is_desktop_app\": false, \"is_native_app\": false, \"is_native_app_apple\": false, \"is_mobile_app_ios\": false, \"is_desktop_app_macos\": false, \"is_aura_app_macos\": false, \"is_aura_web\": false, \"is_sora_ios\": false, \"is_agora_ios\": false, \"is_agora_android\": false, \"is_desktop_app_windows\": false, \"is_electron_app\": false, \"is_mobile_app_android\": false, \"is_mobile_web\": false, \"is_mobile_web_ios\": false, \"is_mobile_web_android\": false, \"is_ios\": false, \"is_android\": false, \"is_macos\": false, \"is_windows\": false, \"is_linux\": true, \"is_chatgpt_client\": false, \"is_sora_client\": false, \"is_agora_client\": false, \"is_browserbased_app\": true, \"is_chatgpt_api\": false, \"is_slack\": false, \"is_chatkit_web\": false, \"is_chatkit_synthetic\": false, \"is_kakao_talk\": false, \"app_version\": null, \"build_number\": null, \"user_agent\": \"mozilla/5.0 (x11; linux x86_64) applewebkit/537.36 (khtml, like gecko) chrome/143.0.0.0 safari/537.36\", \"app_environment\": null, \"os_version\": null, \"device_model\": null, \"user_client_type\": \"desktop_web\"}, \"paragen_stream_type\": \"default\", \"parent_id\": \"ffb05719-6f26-467d-a4de-7e49fbdc85cb\"}, \"recipient\": \"all\", \"channel\": null}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\\n\\nevent: delta\\ndata: {\"p\": \"\", \"o\": \"add\", \"v\": {\"message\": {\"id\": \"71c6e768-8f10-4d5b-80f8-3876d3e5c728\", \"author\": {\"role\": \"assistant\", \"name\": null, \"metadata\": {}}, \"create_time\": 1766471191.769903, \"update_time\": null, \"content\": {\"content_type\": \"text\", \"parts\": [\"\"]}, \"status\": \"in_progress\", \"end_turn\": null, \"weight\": 1.0, \"metadata\": {\"citations\": [], \"content_references\": [], \"request_id\": \"5362bbcc-cd03-46e4-9cb0-52cac1de9606\", \"message_type\": \"next\", \"model_slug\": \"gpt-5-2\", \"default_model_slug\": \"auto\", \"parent_id\": \"101b2a49-34ab-47df-9e37-96039e76c866\", \"turn_exchange_id\": \"abebc94b-1ccf-4fcb-bc3b-91b8f96b6f68\", \"model_switcher_deny\": []}, \"recipient\": \"all\", \"channel\": null}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\", \"error\": null}, \"c\": 0}    \\n\\ndata: {\"type\": \"server_ste_metadata\", \"metadata\": {\"conduit_prewarmed\": false, \"plan_type\": \"guest\", \"user_agent\": \"web_desktop\", \"service\": null, \"fast_convo\": true, \"warmup_state\": \"cold\", \"is_first_turn\": false, \"cluster_region\": \"ukwest\", \"model_slug\": \"i-mini\", \"region\": null, \"is_multimodal\": false, \"did_auto_switch_to_reasoning\": false, \"auto_switcher_race_winner\": null, \"is_autoswitcher_enabled\": false, \"is_search\": null, \"did_prompt_contain_image\": false, \"search_tool_call_count\": null, \"search_tool_query_types\": null, \"message_id\": \"71c6e768-8f10-4d5b-80f8-3876d3e5c728\", \"request_id\": \"5362bbcc-cd03-46e4-9cb0-52cac1de9606\"}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\\n\\ndata: {\"type\": \"message_marker\", \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\", \"message_id\": \"71c6e768-8f10-4d5b-80f8-3876d3e5c728\", \"marker\": \"user_visible_token\", \"event\": \"first\"}\\n\\nevent: delta\\ndata: {\"p\": \"/message/content/parts/0\", \"o\": \"append\", \"v\": \"Sure! Let\\'s\"}    \\n\\nevent: delta\\ndata: {\"v\": \" start by writing\"}      \\n\\nevent: delta\\ndata: {\"v\": \" the **factorial function** in both **Python**\"} \\n\\nevent: delta\\ndata: {\"v\": \" and **Java**, then I\\'ll explain how it works, and show a table of inputs and outputs.\\\\n\\\\n---\\\\n\\\\n### **Factorial\"}       \\n\\nevent: delta\\ndata: {\"v\": \" Explanation**\\\\n\\\\nA **factorial** of a number \\\\\\\\( n \\\\\\\\) (denoted \\\\\\\\(\"}   \\n\\nevent: delta\\ndata: {\"v\": \" n! \\\\\\\\)) is the product of all positive integers less than or equal to \\\\\\\\( n \\\\\\\\).\"}      \\n\\nevent: delta\\ndata: {\"v\": \" It\\\\u2019s defined as:\\\\n\\\\n\\\\\\\\[\\\\nn! = n \\\\\\\\times (n-1)\"}    \\n\\nevent: delta\\ndata: {\"v\": \" \\\\\\\\times (n-2) \\\\\\\\times \\\\\\\\dots \\\\\\\\times 1\\\\n\"}      \\n\\nevent: delta\\ndata: {\"v\": \"\\\\\\\\]\\\\n\\\\n**Special case**: The factorial of 0 is defined as 1\"}    \\n\\nevent: delta\\ndata: {\"v\": \":\\\\n\\\\\\\\[\\\\n0! = 1\\\\n\\\\\\\\]\\\\n\\\\n### **Factorial Function in\"}     \\n\\nevent: delta\\ndata: {\"v\": \" Python**\\\\n\\\\n```python\\\\ndef factorial(n):\\\\n    if n == 0\"}       \\n\\nevent: delta\\ndata: {\"v\": \" or n == 1:\\\\n        return 1\\\\n    else:\\\\n        return n\"}     \\n\\nevent: delta\\ndata: {\"v\": \" * factorial(n - 1)\\\\n\\\\n# Example usage:\\\\nprint(factor\"}  \\n\\nevent: delta\\ndata: {\"v\": \"ial(5))  # Output will be 120\\\\n```\\\\n\\\\n**Explanation**:\\\\n-\"}      \\n\\nevent: delta\\ndata: {\"v\": \" The function uses **recursion**: it calls itself with smaller values of \\\\\\\\( n \\\\\\\\\"}      \\n\\nevent: delta\\ndata: {\"v\": \") until \\\\\\\\( n \\\\\\\\) reaches 1 or 0.\\\\n- If \\\\\\\\( n\"}  \\n\\nevent: delta\\ndata: {\"v\": \" \\\\\\\\) is 0 or 1, it directly returns 1 (base case).\\\\n\\\\n### **\"}   \\n\\nevent: delta\\ndata: {\"v\": \"Factorial Function in Java**\\\\n\\\\n```java\\\\npublic class Factorial {\\\\n    public\"}  \\n\\nevent: delta\\ndata: {\"v\": \" static int factorial(int n) {\\\\n        if (n == 0 ||\"}  \\n\\nevent: delta\\ndata: {\"v\": \" n == 1) {\\\\n            return 1;\\\\n        } else {\\\\n            return\"}\\n\\nevent: delta\\ndata: {\"v\": \" n * factorial(n - 1);\\\\n        }\\\\n    }\\\\n\\\\n    public static\"}  \\n\\nevent: delta\\ndata: {\"v\": \" void main(String[] args) {\\\\n        System.out.println(factorial(5));  //\"}     \\n\\nevent: delta\\ndata: {\"v\": \" Output will be 120\\\\n    }\\\\n}\\\\n```\\\\n\\\\n**Explanation**\"}  \\n\\nevent: delta\\ndata: {\"v\": \":\\\\n- Similar to the Python function, it uses **recursion** to compute the\"}      \\n\\nevent: delta\\ndata: {\"v\": \" factorial.\\\\n- The base case is when \\\\\\\\( n \\\\\\\\) is\"}      \\n\\nevent: delta\\ndata: {\"v\": \" 0 or 1, where the function returns 1.\\\\n\\\\n---\\\\n\\\\n###\"}   \\n\\nevent: delta\\ndata: {\"v\": \" **Sample Table of Input and Outputs**\\\\n\\\\nHere\\'s a table showing the factorials of numbers from\"}\\n\\nevent: delta\\ndata: {\"v\": \" 0 to 5:\\\\n\\\\n| Input (n) | Factorial\"}    \\n\\nevent: delta\\ndata: {\"v\": \" Output (n!) |\\\\n|-----------|-----------------------|\\\\n|\"}       \\n\\nevent: delta\\ndata: {\"v\": \" 0         | 1                     |\\\\n| 1         | 1                    \"}      \\n\\nevent: delta\\ndata: {\"v\": \" |\\\\n| 2         | 2                     |\\\\n| 3         | 6                    \"} \\n\\nevent: delta\\ndata: {\"v\": \" |\\\\n| 4         | 24                    |\\\\n| 5        \"} \\n\\nevent: delta\\ndata: {\"v\": \" | 120                   |\\\\n\\\\n**Explanation of Outputs**:\\\\n- **0! = \"}   \\n\\nevent: delta\\ndata: {\"v\": \"1**: By definition, the factorial of 0 is 1.\\\\n\"} \\n\\nevent: delta\\ndata: {\"v\": \"- **1! = 1**\"}   \\n\\nevent: delta\\ndata: {\"v\": \": 1 multiplied by 1 is 1.\\\\n- **2!\"}      \\n\\nevent: delta\\ndata: {\"v\": \" = 2**: 2 \\\\u00d7 1 = 2.\\\\n-\"}     \\n\\nevent: delta\\ndata: {\"v\": \" **3! = 6**: 3 \\\\u00d7 2 \\\\u00d7 \"}\\n\\nevent: delta\\ndata: {\"v\": \"1 = 6.\\\\n- **4! = 24**: 4 \\\\u00d7\"}\\n\\nevent: delta\\ndata: {\"v\": \" 3 \\\\u00d7 2 \\\\u00d7 1 = 24.\\\\n- **5! =\"}   \\n\\nevent: delta\\ndata: {\"v\": \" 120**: 5 \\\\u00d7 4 \\\\u00d7\"}      \\n\\nevent: delta\\ndata: {\"v\": \" 3 \\\\u00d7 2 \\\\u00d7 1 = \"}\\n\\nevent: delta\\ndata: {\"v\": \"120.\\\\n\\\\n---\\\\n\\\\n\"}\\n\\nevent: delta\\ndata: {\"v\": \"### **Understanding Factorial Growth**\\\\n\\\\nFactorials grow very fast as \\\\\\\\(\"}     \\n\\nevent: delta\\ndata: {\"v\": \" n \\\\\\\\) increases.\"}      \\n\\nevent: delta\\ndata: {\"v\": \" For example:\\\\n- \\\\\\\\(\"}   \\n\\nevent: delta\\ndata: {\"v\": \" 6! = 720 \\\\\\\\)\\\\n- \\\\\\\\( 7!\"}\\n\\nevent: delta\\ndata: {\"v\": \" = 5040 \\\\\\\\)\\\\n- \\\\\\\\( \"}    \\n\\nevent: delta\\ndata: {\"v\": \"10! = 3,628,800 \\\\\\\\)\\\\n\\\\nThis rapid growth is why factorial calculations for large numbers\"}       \\n\\nevent: delta\\ndata: {\"v\": \" can quickly become very large.\\\\n\\\\n\"}    \\n\\nevent: delta\\ndata: {\"v\": \"---\\\\n\\\\nLet me know if you want further\"} \\n\\nevent: delta\\ndata: {\"p\": \"\", \"o\": \"patch\", \"v\": [{\"p\": \"/message/content/parts/0\", \"o\": \"append\", \"v\": \" details or need help with something else!\"}, {\"p\": \"/message/status\", \"o\": \"replace\", \"v\": \"finished_successfully\"}, {\"p\": \"/message/end_turn\", \"o\": \"replace\", \"v\": true}, {\"p\": \"/message/metadata\", \"o\": \"append\", \"v\": {\"finish_details\": {\"type\": \"stop\", \"stop_tokens\": [200002]}, \"is_complete\": true}}]}  \\n\\ndata: {\"type\": \"message_stream_complete\", \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\\n\\ndata: [DONE]\\n\\n'\n",
      ">> https://chatgpt.com/backend-anon/f/conversation\n",
      "Response : event: delta_encoding\n",
      "data: \"v1\"\n",
      "\n",
      "data: {\"type\": \"input_message\", \"input_message\": {\"id\": \"c33882b9-3f9b-4d12-a4b3-92205688efb6\", \"author\": {\"role\": \"user\", \"name\": null, \"metadata\": {}}, \"create_time\": 1766471206.886, \"update_time\": null, \"content\": {\"content_type\": \"text\", \"parts\": [\"You are a coding agent.\\n\\nTask:\\nWrite a Python function factorial(n) that returns n factorial.\\n\\nRules:\\n- Return ONLY valid Python code\\n- Do NOT explain anything\\n- The code must define factorial(n)\"]}, \"status\": \"finished_successfully\", \"end_turn\": null, \"weight\": 1.0, \"metadata\": {\"selected_github_repos\": [], \"selected_all_github_repos\": false, \"serialization_metadata\": {\"custom_symbol_offsets\": []}, \"request_id\": \"cd0c67a9-7e02-441a-8b06-4b244433570b\", \"message_source\": null, \"turn_exchange_id\": \"ae7ad4c2-efe8-4d16-8362-9aac279ee9fe\", \"useragent\": {\"client_type\": \"web\", \"is_mobile\": false, \"is_mobile_app\": false, \"is_desktop_app\": false, \"is_native_app\": false, \"is_native_app_apple\": false, \"is_mobile_app_ios\": false, \"is_desktop_app_macos\": false, \"is_aura_app_macos\": false, \"is_aura_web\": false, \"is_sora_ios\": false, \"is_agora_ios\": false, \"is_agora_android\": false, \"is_desktop_app_windows\": false, \"is_electron_app\": false, \"is_mobile_app_android\": false, \"is_mobile_web\": false, \"is_mobile_web_ios\": false, \"is_mobile_web_android\": false, \"is_ios\": false, \"is_android\": false, \"is_macos\": false, \"is_windows\": false, \"is_linux\": true, \"is_chatgpt_client\": false, \"is_sora_client\": false, \"is_agora_client\": false, \"is_browserbased_app\": true, \"is_chatgpt_api\": false, \"is_slack\": false, \"is_chatkit_web\": false, \"is_chatkit_synthetic\": false, \"is_kakao_talk\": false, \"app_version\": null, \"build_number\": null, \"user_agent\": \"mozilla/5.0 (x11; linux x86_64) applewebkit/537.36 (khtml, like gecko) chrome/143.0.0.0 safari/537.36\", \"app_environment\": null, \"os_version\": null, \"device_model\": null, \"user_client_type\": \"desktop_web\"}, \"paragen_stream_type\": \"default\", \"parent_id\": \"71c6e768-8f10-4d5b-80f8-3876d3e5c728\"}, \"recipient\": \"all\", \"channel\": null}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\n",
      "\n",
      "event: delta\n",
      "data: {\"p\": \"\", \"o\": \"add\", \"v\": {\"message\": {\"id\": \"7f258c9a-51cd-4ef7-a29a-8875b1da95f8\", \"author\": {\"role\": \"assistant\", \"name\": null, \"metadata\": {}}, \"create_time\": 1766471208.463643, \"update_time\": null, \"content\": {\"content_type\": \"text\", \"parts\": [\"\"]}, \"status\": \"in_progress\", \"end_turn\": null, \"weight\": 1.0, \"metadata\": {\"citations\": [], \"content_references\": [], \"request_id\": \"cd0c67a9-7e02-441a-8b06-4b244433570b\", \"message_type\": \"next\", \"model_slug\": \"gpt-5-2\", \"default_model_slug\": \"auto\", \"parent_id\": \"c33882b9-3f9b-4d12-a4b3-92205688efb6\", \"turn_exchange_id\": \"ae7ad4c2-efe8-4d16-8362-9aac279ee9fe\", \"model_switcher_deny\": []}, \"recipient\": \"all\", \"channel\": null}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\", \"error\": null}, \"c\": 0}    \n",
      "\n",
      "data: {\"type\": \"server_ste_metadata\", \"metadata\": {\"conduit_prewarmed\": false, \"plan_type\": \"guest\", \"user_agent\": \"web_desktop\", \"service\": null, \"fast_convo\": true, \"warmup_state\": \"rewarm\", \"is_first_turn\": false, \"cluster_region\": \"ukwest\", \"model_slug\": \"i-mini\", \"region\": null, \"is_multimodal\": false, \"did_auto_switch_to_reasoning\": false, \"auto_switcher_race_winner\": null, \"is_autoswitcher_enabled\": false, \"is_search\": null, \"did_prompt_contain_image\": false, \"search_tool_call_count\": null, \"search_tool_query_types\": null, \"message_id\": \"7f258c9a-51cd-4ef7-a29a-8875b1da95f8\", \"request_id\": \"cd0c67a9-7e02-441a-8b06-4b244433570b\"}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\n",
      "\n",
      "data: {\"type\": \"message_marker\", \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\", \"message_id\": \"7f258c9a-51cd-4ef7-a29a-8875b1da95f8\", \"marker\": \"user_visible_token\", \"event\": \"first\"}\n",
      "\n",
      "event: delta\n",
      "data: {\"p\": \"/message/content/parts/0\", \"o\": \"append\", \"v\": \"```python\"}      \n",
      "\n",
      "event: delta\n",
      "data: {\"v\": \"\\n\"}     \n",
      "\n",
      "event: delta\n",
      "data: {\"v\": \"def factorial(n):\\n    if n == \"}\n",
      "\n",
      "event: delta\n",
      "data: {\"p\": \"\", \"o\": \"patch\", \"v\": [{\"p\": \"/message/content/parts/0\", \"o\": \"append\", \"v\": \"0 or n == 1:\\n        return 1\\n    else:\\n        return n * factorial(n - 1)\\n```\"}, {\"p\": \"/message/status\", \"o\": \"replace\", \"v\": \"finished_successfully\"}, {\"p\": \"/message/end_turn\", \"o\": \"replace\", \"v\": true}, {\"p\": \"/message/metadata\", \"o\": \"append\", \"v\": {\"finish_details\": {\"type\": \"stop\", \"stop_tokens\": [200002]}, \"is_complete\": true}}]} \n",
      "\n",
      "data: {\"type\": \"message_stream_complete\", \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\n",
      "\n",
      "data: [DONE]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "async with Stealth().use_async(async_playwright()) as p:\n",
    "    browser = await p.chromium.launch(headless = False)\n",
    "    page = await browser.new_page()\n",
    "    # page.on(\"request\", lambda request: print(\">>\", request.method, request.url))\n",
    "    page.on(\"response\", handle_response)\n",
    "    await page.goto(\"https://chatgpt.com/\")\n",
    "\n",
    "    msg_input = page.locator('//textarea[@name=\"prompt-textarea\"]')\n",
    "\n",
    "    msg = '''\n",
    "hi\n",
    "mate\n",
    "'''\n",
    "\n",
    "    # input(\"Press Enter to close...\")\n",
    "    \n",
    "    await simulate_user_type(msg, msg_input, page)\n",
    "    # await msg_input.type('\\n')\n",
    "    # Use a glob url pattern\n",
    "    async with page.expect_response(\"**/conversation\") as response_info:\n",
    "        await page.locator('//button[@data-testid=\"send-button\"]').click()\n",
    "\n",
    "    response = await response_info.value\n",
    "    print(\"Response :\", await response.body())\n",
    "\n",
    "    last_copy_button_xpath = '//article[@data-turn=\"assistant\" and @data-scroll-anchor=\"true\"][last()]//button[@aria-label=\"Copy\" and @data-state=\"closed\"]'\n",
    "    await page.locator(last_copy_button_xpath).wait_for(state='visible', timeout=60000)\n",
    "    await page.evaluate(f\"\"\"\n",
    "        const element = document.evaluate('{last_copy_button_xpath}', document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n",
    "        if (element) {{\n",
    "            element.remove();\n",
    "        }}\n",
    "    \"\"\")\n",
    "    response = await page.locator('//article[@data-turn=\"assistant\" and @data-scroll-anchor=\"true\"][last()]//div[contains(@class,\"markdown\")]').text_content()\n",
    "    responses.append(response)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "\n",
    "    msg = 'write factorial function with python and java and explain it and show me a sample table of input and outputs and explain more'\n",
    "\n",
    "    # input(\"Press Enter to close...\")\n",
    "    \n",
    "    await simulate_user_type(msg, msg_input, page)\n",
    "    # await msg_input.type('\\n')\n",
    "    # Use a glob url pattern\n",
    "    async with page.expect_response(\"**/conversation\") as response_info:\n",
    "        await page.locator('//button[@data-testid=\"send-button\"]').click()\n",
    "\n",
    "    response = await response_info.value\n",
    "    print(\"Response :\", await response.body())\n",
    "\n",
    "    await page.locator(last_copy_button_xpath).wait_for(state='visible', timeout=60000)\n",
    "    await page.evaluate(f\"\"\"\n",
    "        const element = document.evaluate('{last_copy_button_xpath}', document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n",
    "        if (element) {{\n",
    "            element.remove();\n",
    "        }}\n",
    "    \"\"\")\n",
    "    response = await page.locator('//article[@data-turn=\"assistant\" and @data-scroll-anchor=\"true\"][last()]//div[contains(@class,\"markdown\")]').text_content()\n",
    "    responses.append(response)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "\n",
    "    msg = '''You are a coding agent.\n",
    "\n",
    "Task:\n",
    "Write a Python function factorial(n) that returns n factorial.\n",
    "\n",
    "Rules:\n",
    "- Return ONLY valid Python code\n",
    "- Do NOT explain anything\n",
    "- The code must define factorial(n)'''\n",
    "\n",
    "    # input(\"Press Enter to close...\")\n",
    "    \n",
    "    await simulate_user_type(msg, msg_input, page)\n",
    "    # //button[@data-testid=\"send-button\"]\n",
    "    # await msg_input.type('\\n')\n",
    "    # Use a glob url pattern\n",
    "    async with page.expect_response(\"**/conversation\") as response_info:\n",
    "        await page.locator('//button[@data-testid=\"send-button\"]').click()\n",
    "\n",
    "    last_response = await response_info.value\n",
    "    last_response = await last_response.text()\n",
    "    print(\"Response :\", last_response)\n",
    "\n",
    "    await page.locator(last_copy_button_xpath).wait_for(state='visible', timeout=60000)\n",
    "    await page.evaluate(f\"\"\"\n",
    "        const element = document.evaluate('{last_copy_button_xpath}', document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n",
    "        if (element) {{\n",
    "            element.remove();\n",
    "        }}\n",
    "    \"\"\")\n",
    "    response = await page.locator('//article[@data-turn=\"assistant\" and @data-scroll-anchor=\"true\"][last()]//div[contains(@class,\"markdown\")]').text_content()\n",
    "    responses.append(response)\n",
    "\n",
    "    input(\"Press Enter to close...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab4c737a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hey! What's up, mate? How’s it going?\",\n",
       " \"Sure! Let's start by writing the factorial function in both Python and Java, then I'll explain how it works, and show a table of inputs and outputs.\\n\\nFactorial Explanation\\nA factorial of a number nnn (denoted n!n!n!) is the product of all positive integers less than or equal to nnn. It’s defined as:\\nn!=n×(n−1)×(n−2)×⋯×1n! = n \\\\times (n-1) \\\\times (n-2) \\\\times \\\\dots \\\\times 1n!=n×(n−1)×(n−2)×⋯×1\\nSpecial case: The factorial of 0 is defined as 1:\\n0!=10! = 10!=1\\nFactorial Function in Python\\npythonCopy codedef factorial(n):\\n    if n == 0 or n == 1:\\n        return 1\\n    else:\\n        return n * factorial(n - 1)\\n\\n# Example usage:\\nprint(factorial(5))  # Output will be 120\\n\\nExplanation:\\n\\n\\nThe function uses recursion: it calls itself with smaller values of nnn until nnn reaches 1 or 0.\\n\\n\\nIf nnn is 0 or 1, it directly returns 1 (base case).\\n\\n\\nFactorial Function in Java\\njavaCopy codepublic class Factorial {\\n    public static int factorial(int n) {\\n        if (n == 0 || n == 1) {\\n            return 1;\\n        } else {\\n            return n * factorial(n - 1);\\n        }\\n    }\\n\\n    public static void main(String[] args) {\\n        System.out.println(factorial(5));  // Output will be 120\\n    }\\n}\\n\\nExplanation:\\n\\n\\nSimilar to the Python function, it uses recursion to compute the factorial.\\n\\n\\nThe base case is when nnn is 0 or 1, where the function returns 1.\\n\\n\\n\\nSample Table of Input and Outputs\\nHere's a table showing the factorials of numbers from 0 to 5:\\nInput (n)Factorial Output (n!)011122364245120\\nExplanation of Outputs:\\n\\n\\n0! = 1: By definition, the factorial of 0 is 1.\\n\\n\\n1! = 1: 1 multiplied by 1 is 1.\\n\\n\\n2! = 2: 2 × 1 = 2.\\n\\n\\n3! = 6: 3 × 2 × 1 = 6.\\n\\n\\n4! = 24: 4 × 3 × 2 × 1 = 24.\\n\\n\\n5! = 120: 5 × 4 × 3 × 2 × 1 = 120.\\n\\n\\n\\nUnderstanding Factorial Growth\\nFactorials grow very fast as nnn increases. For example:\\n\\n\\n6!=7206! = 7206!=720\\n\\n\\n7!=50407! = 50407!=5040\\n\\n\\n10!=3,628,80010! = 3,628,80010!=3,628,800\\n\\n\\nThis rapid growth is why factorial calculations for large numbers can quickly become very large.\\n\\nLet me know if you want further details or need help with something else!\",\n",
       " 'pythonCopy codedef factorial(n):\\n    if n == 0 or n == 1:\\n        return 1\\n    else:\\n        return n * factorial(n - 1)\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56905282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'event: delta_encoding\\ndata: \"v1\"\\n\\ndata: {\"type\": \"input_message\", \"input_message\": {\"id\": \"c33882b9-3f9b-4d12-a4b3-92205688efb6\", \"author\": {\"role\": \"user\", \"name\": null, \"metadata\": {}}, \"create_time\": 1766471206.886, \"update_time\": null, \"content\": {\"content_type\": \"text\", \"parts\": [\"You are a coding agent.\\\\n\\\\nTask:\\\\nWrite a Python function factorial(n) that returns n factorial.\\\\n\\\\nRules:\\\\n- Return ONLY valid Python code\\\\n- Do NOT explain anything\\\\n- The code must define factorial(n)\"]}, \"status\": \"finished_successfully\", \"end_turn\": null, \"weight\": 1.0, \"metadata\": {\"selected_github_repos\": [], \"selected_all_github_repos\": false, \"serialization_metadata\": {\"custom_symbol_offsets\": []}, \"request_id\": \"cd0c67a9-7e02-441a-8b06-4b244433570b\", \"message_source\": null, \"turn_exchange_id\": \"ae7ad4c2-efe8-4d16-8362-9aac279ee9fe\", \"useragent\": {\"client_type\": \"web\", \"is_mobile\": false, \"is_mobile_app\": false, \"is_desktop_app\": false, \"is_native_app\": false, \"is_native_app_apple\": false, \"is_mobile_app_ios\": false, \"is_desktop_app_macos\": false, \"is_aura_app_macos\": false, \"is_aura_web\": false, \"is_sora_ios\": false, \"is_agora_ios\": false, \"is_agora_android\": false, \"is_desktop_app_windows\": false, \"is_electron_app\": false, \"is_mobile_app_android\": false, \"is_mobile_web\": false, \"is_mobile_web_ios\": false, \"is_mobile_web_android\": false, \"is_ios\": false, \"is_android\": false, \"is_macos\": false, \"is_windows\": false, \"is_linux\": true, \"is_chatgpt_client\": false, \"is_sora_client\": false, \"is_agora_client\": false, \"is_browserbased_app\": true, \"is_chatgpt_api\": false, \"is_slack\": false, \"is_chatkit_web\": false, \"is_chatkit_synthetic\": false, \"is_kakao_talk\": false, \"app_version\": null, \"build_number\": null, \"user_agent\": \"mozilla/5.0 (x11; linux x86_64) applewebkit/537.36 (khtml, like gecko) chrome/143.0.0.0 safari/537.36\", \"app_environment\": null, \"os_version\": null, \"device_model\": null, \"user_client_type\": \"desktop_web\"}, \"paragen_stream_type\": \"default\", \"parent_id\": \"71c6e768-8f10-4d5b-80f8-3876d3e5c728\"}, \"recipient\": \"all\", \"channel\": null}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\\n\\nevent: delta\\ndata: {\"p\": \"\", \"o\": \"add\", \"v\": {\"message\": {\"id\": \"7f258c9a-51cd-4ef7-a29a-8875b1da95f8\", \"author\": {\"role\": \"assistant\", \"name\": null, \"metadata\": {}}, \"create_time\": 1766471208.463643, \"update_time\": null, \"content\": {\"content_type\": \"text\", \"parts\": [\"\"]}, \"status\": \"in_progress\", \"end_turn\": null, \"weight\": 1.0, \"metadata\": {\"citations\": [], \"content_references\": [], \"request_id\": \"cd0c67a9-7e02-441a-8b06-4b244433570b\", \"message_type\": \"next\", \"model_slug\": \"gpt-5-2\", \"default_model_slug\": \"auto\", \"parent_id\": \"c33882b9-3f9b-4d12-a4b3-92205688efb6\", \"turn_exchange_id\": \"ae7ad4c2-efe8-4d16-8362-9aac279ee9fe\", \"model_switcher_deny\": []}, \"recipient\": \"all\", \"channel\": null}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\", \"error\": null}, \"c\": 0}    \\n\\ndata: {\"type\": \"server_ste_metadata\", \"metadata\": {\"conduit_prewarmed\": false, \"plan_type\": \"guest\", \"user_agent\": \"web_desktop\", \"service\": null, \"fast_convo\": true, \"warmup_state\": \"rewarm\", \"is_first_turn\": false, \"cluster_region\": \"ukwest\", \"model_slug\": \"i-mini\", \"region\": null, \"is_multimodal\": false, \"did_auto_switch_to_reasoning\": false, \"auto_switcher_race_winner\": null, \"is_autoswitcher_enabled\": false, \"is_search\": null, \"did_prompt_contain_image\": false, \"search_tool_call_count\": null, \"search_tool_query_types\": null, \"message_id\": \"7f258c9a-51cd-4ef7-a29a-8875b1da95f8\", \"request_id\": \"cd0c67a9-7e02-441a-8b06-4b244433570b\"}, \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\\n\\ndata: {\"type\": \"message_marker\", \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\", \"message_id\": \"7f258c9a-51cd-4ef7-a29a-8875b1da95f8\", \"marker\": \"user_visible_token\", \"event\": \"first\"}\\n\\nevent: delta\\ndata: {\"p\": \"/message/content/parts/0\", \"o\": \"append\", \"v\": \"```python\"}      \\n\\nevent: delta\\ndata: {\"v\": \"\\\\n\"}     \\n\\nevent: delta\\ndata: {\"v\": \"def factorial(n):\\\\n    if n == \"}\\n\\nevent: delta\\ndata: {\"p\": \"\", \"o\": \"patch\", \"v\": [{\"p\": \"/message/content/parts/0\", \"o\": \"append\", \"v\": \"0 or n == 1:\\\\n        return 1\\\\n    else:\\\\n        return n * factorial(n - 1)\\\\n```\"}, {\"p\": \"/message/status\", \"o\": \"replace\", \"v\": \"finished_successfully\"}, {\"p\": \"/message/end_turn\", \"o\": \"replace\", \"v\": true}, {\"p\": \"/message/metadata\", \"o\": \"append\", \"v\": {\"finish_details\": {\"type\": \"stop\", \"stop_tokens\": [200002]}, \"is_complete\": true}}]} \\n\\ndata: {\"type\": \"message_stream_complete\", \"conversation_id\": \"694a3613-3878-8010-89a0-66a7624b67d6\"}\\n\\ndata: [DONE]\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "282f0504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ryayoung/chatgpt-schema/blob/3a8dc854a6cf4fe66e0961e5127c8f443ddf8d06/scripts/parse_stream.py#L24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fba98da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Response:```python\n",
      "def factorial(n):\n",
      "    if n == 0 or n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return n * factorial(n - 1)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def parse_gpt_response(stream_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Parse the stream response and extract the clean GPT message.\n",
    "    Returns the concatenated text from the assistant's content.\n",
    "    \"\"\"\n",
    "    # Step 1: Clean up prefixes and suffixes\n",
    "    text_tmp1 = stream_text[33:] if stream_text.startswith(\"event: delta_encoding\") else stream_text\n",
    "    text_tmp1 = text_tmp1[7:] if text_tmp1.startswith(\"\\ndata: \") else text_tmp1\n",
    "    if text_tmp1.endswith(\"\\n\\ndata: [DONE]\\n\\n\"):\n",
    "        text_tmp2 = text_tmp1[:-16]\n",
    "    else:\n",
    "        text_tmp2 = text_tmp1\n",
    "    \n",
    "    # Step 2: Split into JSON chunks\n",
    "    text_list = []\n",
    "    for x in text_tmp2.replace(\"event: delta\", \"\").split(\"\\n\\ndata: \"):\n",
    "        if x.strip():  # Skip empty\n",
    "            tmp1 = x.strip()\n",
    "            # Fix if not starting/ending with {} properly\n",
    "            if not tmp1.startswith(\"{\"):\n",
    "                start_index = tmp1.find(\"{\")\n",
    "                if start_index != -1:\n",
    "                    tmp1 = tmp1[start_index:]\n",
    "            if not tmp1.endswith(\"}\"):\n",
    "                end_index = tmp1.rfind(\"}\")\n",
    "                if end_index != -1:\n",
    "                    tmp1 = tmp1[:end_index + 1]\n",
    "            # Try to load as JSON\n",
    "            try:\n",
    "                tmp = json.loads(tmp1)\n",
    "            except json.JSONDecodeError:\n",
    "                # Fix escaped backslashes if needed\n",
    "                tmp2 = tmp1.replace(\"\\\\\\\\\", \"\\\\\")\n",
    "                try:\n",
    "                    tmp = json.loads(tmp2)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue  # Skip invalid chunks\n",
    "            text_list.append(tmp)\n",
    "    \n",
    "    # Step 3: Find start of content and extract text\n",
    "    first_begin = [i for i, msg in enumerate(text_list) if msg.get(\"p\") == \"/message/content/parts/0\"]\n",
    "    begin = first_begin[0] if first_begin else 0\n",
    "    msg_list = \"\"\n",
    "    for index, msg in enumerate(text_list):\n",
    "        if index >= begin:\n",
    "            # Simple string append\n",
    "            if \"v\" in msg and isinstance(msg[\"v\"], str):\n",
    "                msg_list += msg[\"v\"]\n",
    "            # List handling (nested parts)\n",
    "            elif \"v\" in msg and isinstance(msg[\"v\"], list):\n",
    "                for x in msg[\"v\"]:\n",
    "                    if \"p\" in x and x[\"p\"] == \"/message/content/parts/0\" and \"v\" in x:\n",
    "                        msg_list += x[\"v\"]\n",
    "                    # Deeper patch nesting\n",
    "                    if \"p\" in x and x[\"p\"] == \"\" and \"o\" in x and x[\"o\"] == \"patch\" and \"v\" in x and isinstance(x[\"v\"], list):\n",
    "                        for sub in x[\"v\"]:\n",
    "                            if \"p\" in sub and sub[\"p\"] == \"/message/content/parts/0\" and \"v\" in sub:\n",
    "                                msg_list += sub[\"v\"]\n",
    "    \n",
    "    # Step 4: Clean special patterns (if any, like in the original)\n",
    "    if \"turn0\" in msg_list or \"city\" in msg_list:\n",
    "        pattern = r'[\\ue200-\\ue203]?([a-z]+)?[\\ue200-\\ue203](?:turn\\d+(?:image|search|fetch|forecast)\\d+|city)'\n",
    "        msg_list = re.sub(pattern, '', msg_list)\n",
    "    \n",
    "    return msg_list.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Parse کن و نمایش بده\n",
    "parsed_message = parse_gpt_response(last_response)\n",
    "print(f\"GPT Response:{parsed_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c9abe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```python\\ndef factorial(n):\\n    if n == 0 or n == 1:\\n        return 1\\n    else:\\n        return n * factorial(n - 1)\\n```'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
